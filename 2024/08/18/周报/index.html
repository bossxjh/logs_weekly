

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/logs_weekly/img/fluid.png">
  <link rel="icon" href="/logs_weekly/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jiahao Xiao">
  <meta name="keywords" content="">
  
    <meta name="description" content="周报｜｜日期：2024.8.26-8.302024年8月26日 - 2024年8月30日 本周工作内容： 完成的任务   发现两种架构的区别：  图像视频特征融合 → FC 层 → 分数     直接通过 FC 层输出分数: 效果主要依赖于初始提取的图像特征。如果特征已经高度凝练且有足够的信息，那么这种方法可能表现得不错。然而，如果图像特征不够丰富，这种方法的性能可能有限。      图像视频特征">
<meta property="og:type" content="article">
<meta property="og:title" content="周报">
<meta property="og:url" content="http://example.com/2024/08/18/%E5%91%A8%E6%8A%A5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="周报｜｜日期：2024.8.26-8.302024年8月26日 - 2024年8月30日 本周工作内容： 完成的任务   发现两种架构的区别：  图像视频特征融合 → FC 层 → 分数     直接通过 FC 层输出分数: 效果主要依赖于初始提取的图像特征。如果特征已经高度凝练且有足够的信息，那么这种方法可能表现得不错。然而，如果图像特征不够丰富，这种方法的性能可能有限。      图像视频特征">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://notes.sjtu.edu.cn/uploads/upload_fee2a1272dfe1ea80ee3e398325069a2.jpg">
<meta property="og:image" content="https://notes.sjtu.edu.cn/uploads/upload_acdae1770e2d9f0da028715754b34a17.jpg">
<meta property="article:published_time" content="2024-08-18T08:13:52.000Z">
<meta property="article:modified_time" content="2024-08-30T04:12:34.900Z">
<meta property="article:author" content="Jiahao Xiao">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://notes.sjtu.edu.cn/uploads/upload_fee2a1272dfe1ea80ee3e398325069a2.jpg">
  
  
  
  <title>周报 - Hexo</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/logs_weekly/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/logs_weekly/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/logs_weekly/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/logs_weekly/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/logs_weekly/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/logs_weekly/js/utils.js" ></script>
  <script  src="/logs_weekly/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/logs_weekly/">
      <strong>Fluid</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/logs_weekly/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/logs_weekly/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/logs_weekly/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/logs_weekly/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/logs_weekly/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/logs_weekly/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="周报"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.5k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          63 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">周报</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="周报"><a href="#周报" class="headerlink" title="周报"></a>周报</h1><h3 id="｜｜日期：2024-8-26-8-30"><a href="#｜｜日期：2024-8-26-8-30" class="headerlink" title="｜｜日期：2024.8.26-8.30"></a>｜｜日期：2024.8.26-8.30</h3><p>2024年8月26日 - 2024年8月30日</p>
<h4 id="本周工作内容："><a href="#本周工作内容：" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><strong>完成的任务</strong></li>
</ol>
<ul>
<li>发现两种架构的区别：</li>
<li><ul>
<li>图像视频特征融合 → FC 层 → 分数</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>直接通过 FC 层输出分数: 效果主要依赖于初始提取的图像特征。如果特征已经高度凝练且有足够的信息，那么这种方法可能表现得不错。然而，如果图像特征不够丰富，这种方法的性能可能有限。</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>图像视频特征融合 → 语言模型 → 隐藏层输出 → FC 层 → 分数</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>通过语言模型处理后再输出分数: 这种方法通常在处理复杂任务时表现更好，尤其是在需要考虑特征之间复杂交互和上下文依赖的任务中。通过语言模型的处理，最终的分数输出往往更加精准和可靠。不过，这种方法对数据的要求更高，训练过程也更复杂。</li>
</ul>
</li>
</ul>
</li>
<li>搭建模型架构,我是用：HVS+LLaVA （但是我看了看Q-Align的，我感觉可能用Q-Align会更好？？因为Q-Align针对图像、语言特征融合有优化啊）</li>
<li><ul>
<li>使用之前修改好的输出层是浮点数的LLaVA。</li>
</ul>
</li>
<li><ul>
<li>单独跑HVS，输出融合了<br>Temporal形状是：[Video_length&#x2F;2,temporal_features_size]:([120,512])<br>和Spatial形状是[Video_length,Spatial_features_size]:([240,8192])特征的视频特征Fused_HVS_features形状是[Video_length&#x2F;2,temporal_features_size]:([120,8704])</li>
</ul>
</li>
<li><ul>
<li>然后把Fused_HVS_features[Video_length&#x2F;2,temporal_features_size+Spatial_features_size]和llava最后一层的输出特征：llava_features[video_length,hidden_size]:([240,4096])进行融合：经过一个融合模块： 最后输出video_fused_features:[video_length,hidden_size+temporal_features_size+Spatial_features_size]，经过一个简单线性层，直接到一个视频分数。<details>
<summary>融合模块代码</summary>

   class CrossGatingBlock(nn.Module):<br>def <strong>init</strong>(self, input_size_1, input_size_2):<br>    super(CrossGatingBlock, self).<strong>init</strong>()<br>    self.dense_x1 &#x3D; nn.Linear(input_size_1, input_size_1)<br>    self.dense_x2 &#x3D; nn.Linear(input_size_2, input_size_2)<br>    self.gelu &#x3D; nn.GELU()<br>    self.layer_norm_1 &#x3D; nn.LayerNorm(input_size_1)<br>    self.layer_norm_2 &#x3D; nn.LayerNorm(input_size_2)<br>    self.multi_axis_cross_gating &#x3D; nn.Linear(input_size_2, input_size_1)<br><br>def forward(self, x, y):<br>    x1 &#x3D; self.dense_x1(x)<br>    y1 &#x3D; self.dense_x2(y)<br><br>    x1 &#x3D; self.gelu(x1)<br>    y1 &#x3D; self.gelu(y1)<br><br>    x1 &#x3D; self.layer_norm_1(x1)<br>    y1 &#x3D; self.layer_norm_2(y1)<br><br>    # Multi-axis Cross Gating<br>    gated_x &#x3D; self.multi_axis_cross_gating(y1)<br>    gated_y &#x3D; self.multi_axis_cross_gating(x1)<br><br>    x2 &#x3D; x1 * torch.sigmoid(gated_x)<br>    y2 &#x3D; y1 * torch.sigmoid(gated_y)<br><br>    x3 &#x3D; x + x2<br>    y3 &#x3D; y + y2<br><br>    return x3, y3<br>def fuse_features(llava_features, HVS_features):<br># Initialize CrossGatingBlock with appropriate input sizes<br>cgb &#x3D; CrossGatingBlock(input_size_1&#x3D;4096, input_size_2&#x3D;8704)<br><br># Forward pass through CrossGatingBlock<br>fused_llava, fused_HVS &#x3D; cgb(llava_features, HVS_features)<br><br># Concatenate the fused features along the last dimension<br>fused_output &#x3D; torch.cat((fused_llava, fused_HVS), dim&#x3D;-1)<br><br>return fused_output</li>
</ul>
</li>
</ul>
</details>

<details>
    <summary>原理架构</summary>
    
<p><img src="https://notes.sjtu.edu.cn/uploads/upload_fee2a1272dfe1ea80ee3e398325069a2.jpg" srcset="/logs_weekly/img/loading.gif" lazyload></p>
</details>




<ol start="2">
<li><strong>正在进行的任务</strong><br><img src="https://notes.sjtu.edu.cn/uploads/upload_acdae1770e2d9f0da028715754b34a17.jpg" srcset="/logs_weekly/img/loading.gif" lazyload></li>
</ol>
<ul>
<li>架构大体上已经改好了，只是现在在调试debug一些小地方。</li>
</ul>
<ol start="3">
<li><strong>待办事项</strong></li>
</ol>
<ul>
<li>完成TVQA-C的训练和结果复现。</li>
</ul>
<h4 id="学到的新的小知识或技能："><a href="#学到的新的小知识或技能：" class="headerlink" title="学到的新的小知识或技能："></a>学到的新的小知识或技能：</h4><ul>
<li>现在改模型结构越来越熟练了，改得比上周改浮点数输出要快得很多。happy</li>
</ul>
<h4 id="问题和困难："><a href="#问题和困难：" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li>显存不足以同时加载三个模型（llava ， temporal，spatial） 后面俩个只能动态加载</li>
<li>两个模型的环境不一样。目前是，我就在llava的环境里下了一些HVS的模型和库，目前运行没有环境冲突上的错误，但不知道会不会有潜在的错误在。</li>
</ul>
<h3 id="｜｜日期：2024-8-19-8-23"><a href="#｜｜日期：2024-8-19-8-23" class="headerlink" title="｜｜日期：2024.8.19-8.23"></a>｜｜日期：2024.8.19-8.23</h3><p>2024年8月19日 - 2024年8月23日</p>
<h4 id="本周工作内容：-1"><a href="#本周工作内容：-1" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><strong>完成的任务</strong></li>
</ol>
<ul>
<li>修改模型的输出层<details>
  <summary>细节</summary>
 两种方法耶：直接把4096（hidden_size)变为1；或者先把4096变为32000（也就是这里不动），然后在新加一个32000到1的线性层。我是使用了直接把4096（hidden_size)变为1的方法。但不知道且好奇这两种方法的效果哪种好？
  
<ul>
<li>generation模块的输出层修改；forward模块输出层修改</li>
<li>修改了绑定的函数，解绑了输出和输入层</li>
<li>调试修改模型的加载权重的逻辑，使得不加载旧的输出全连接层的权重，把新的权重按照 nn.init.normal_(module.weight, mean&#x3D;0.0, std&#x3D;0.02)逻辑初始化。</li>
</ul>
</li>
</ul>
</details>

<ul>
<li><p>学习别的5组的实现方法</p>
<ul>
<li><ul>
<li>TVQA-C<ul>
<li><ul>
<li><ul>
<li>使用了HVS-5M来提取视频特征（运动特征，空间特征）；结合利用Q-Align，加强了帧图像的语意特征；特征融合后全联接层到输出。</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>训练的loss就是 PLCC loss and SROCC loss和KROCC loss，采用的是组策略。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>SJTU-MultimediaLab</li>
<li><ul>
<li><ul>
<li>用slowfast、swim-transformer-B、LIQE（与语意信息失真类型相关的特征）、Q-Align、fast-VQA（局部感知特征）、D3D（视频压缩信息特征；融合所有特征后，用了GELU的全联接层</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>FudanVIP<ul>
<li><ul>
<li><ul>
<li>clip分别CNN、swim-transform特征融合，得到包括自己独立在内点三个分数，然后相加</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>看Fudan-VIP的启示：我自己的只有基于语义特征的分支耶</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>Test IQA<ul>
<li><ul>
<li><ul>
<li>用 Discrete Cosine Transform (DCT) and Wavelet提取非学习的特征，然后就可以有各种侧重点的指标：VSI、sm-ssim之类的，然后就用一个模型来学习融合这些各种指标角度生成分数</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>VPT<ul>
<li><ul>
<li><ul>
<li>用Q-Align，一个是输入切割的图片（关注局部特征），一个输入放缩的图片（关注全局特征）；然后评分5级和8级，两者再加权平均。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ol start="2">
<li><strong>正在进行的任务</strong></li>
</ol>
<ul>
<li>修改训练的时候的target加载逻辑，需要去除他原本的tokenize的过程，采取浮点数的形式。</li>
<li>训练输出格式是浮点数的模型</li>
</ul>
<ol start="3">
<li><strong>待办事项</strong></li>
</ol>
<ul>
<li>测评输出格式是浮点数的模型的效果</li>
<li>修改输入：多图片输入（依次并行都经过视觉编码器变为了语言层之后在整合）</li>
<li>修改输入：多图片输入（先把多张图像（相当于3维了）整合为2维然后在输入到视觉编码器）</li>
</ul>
<h4 id="学到的新的小知识或技能：-1"><a href="#学到的新的小知识或技能：-1" class="headerlink" title="学到的新的小知识或技能："></a>学到的新的小知识或技能：</h4><ul>
<li>vscode调试功能的熟练使用来debug和跟踪数据流。</li>
<li>粗略了解到了很多新的工具：HVS-5M、Q-Align、slowfast方法、GELU</li>
<li>看了别的组的画的图（作图可以标注“参数锁没锁”之列的啊），给方法取名字啊</li>
</ul>
<h4 id="问题和困难：-1"><a href="#问题和困难：-1" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li>感觉自己的习惯不是很好，东改西改，都不知道自己最后改动了哪些地方了。</li>
</ul>
<h4 id="个人的感想和反思："><a href="#个人的感想和反思：" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>看了别人的方法，发现就是积累？把了解到的可以抽取特征的模型都堆砌在一起就好了？；（比如GELU，可以看到线性层就加个这个进去；还有就是Q-Align，也是只要是有语言语意特征的也就直接加进去就好了。？）</p>
<h3 id="｜｜日期：2024-7-27-8-2"><a href="#｜｜日期：2024-7-27-8-2" class="headerlink" title="｜｜日期：2024.7.27-8.2"></a>｜｜日期：2024.7.27-8.2</h3><p>2024年7月27日 - 2024年8月2日</p>
<h4 id="本周工作内容：-2"><a href="#本周工作内容：-2" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><strong>完成的任务</strong></li>
</ol>
<ul>
<li>项目整理归档，给出运行项目所需环境，和README文件</li>
<li>下载并测评final test dataset</li>
<li>编写solution description with a pipeline architecture diagram</li>
<li>看论文CMC-Bench</li>
</ul>
<ol start="2">
<li><strong>正在进行的任务</strong></li>
</ol>
<ul>
<li>整理项目文件到自己的github上</li>
<li>论文Video compression dataset and benchmark of learning-based video-quality metrics <a target="_blank" rel="noopener" href="https://openreview.net/pdf?id=My5AI9aM49R">https://openreview.net/pdf?id=My5AI9aM49R</a></li>
</ul>
<ol start="3">
<li><strong>代办事项</strong></li>
</ol>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/XPixelGroup/DepictQA">https://github.com/XPixelGroup/DepictQA</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2405.18842">https://arxiv.org/pdf/2405.18842</a></li>
</ul>
<ol start="4">
<li><strong>后续工作</strong></li>
</ol>
<ul>
<li>我想要去做实验去看看一下“计算loss是通过引入加权机制，就可以让交叉熵也能接近MSE”的方法的效果到底咋样，有没有效果</li>
<li>修改模型的三个方向：</li>
<li><ul>
<li>1.修改模型输出为浮点数</li>
</ul>
</li>
<li><ul>
<li>2.修改输入：多图片输入（依次并行都经过视觉编码器变为了语言层之后在整合）</li>
</ul>
</li>
<li><ul>
<li>3.修改输入：多图片输入（先把多张图像（相当于3维了）整合为2维然后在输入到视觉编码器）</li>
</ul>
</li>
</ul>
<h4 id="学到的新的小知识或技能：-2"><a href="#学到的新的小知识或技能：-2" class="headerlink" title="学到的新的小知识或技能："></a>学到的新的小知识或技能：</h4><ul>
<li>利用drawio画论文里的图</li>
<li>LaTex的使用</li>
<li>“Mega有20G的免费云盘空间”</li>
</ul>
<h4 id="问题和困难：-2"><a href="#问题和困难：-2" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li>提问：要怎么很方便的第一时间关注到前沿新出的知识、工具、论文之类的啊。我获取这些信息的地方都很散乱（我目前还是抖音、b站、chatgpt、总结性的论文或者是我搜索一篇论文的时候它有推荐另一篇才知道）；；；；；（是可以订阅啥学术期刊、博客和新闻网站，学术资源平台，或聚合工具，课程与会议或是啥邮件订阅与新闻通讯之类的可以很系统的全面的获取信息的吗？？？？）</li>
</ul>
<h4 id="个人的感想和反思：-1"><a href="#个人的感想和反思：-1" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>发现自己学习新工具的速度还是很快的（LaTex，drawio之类的）；<br>这个星期，花了一部分时间在托福学习上，在这个上面化的时间稍稍减少。</p>
<h3 id="｜｜日期：2024-7-20-7-26"><a href="#｜｜日期：2024-7-20-7-26" class="headerlink" title="｜｜日期：2024.7.20-7.26"></a>｜｜日期：2024.7.20-7.26</h3><p>2024年7月20日 - 2024年7月26日</p>
<h4 id="本周工作内容：-3"><a href="#本周工作内容：-3" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><strong>完成事项</strong></li>
</ol>
<ul>
<li>改用pytorch-msssim和yuv格式测试</li>
<li>bpgenc的测试分数</li>
<li>三个分数的组合方式 怎样分数最高？？（ms-ssim、niqe、bpgenc）（在训练集上表现好，但是在测试集上没用，那就是过拟合了）</li>
<li>怎么去提高训练效果：尝试加权交叉熵（因为两个数字越接近，那肯定越高位的数字越需要相同）</li>
<li>自己构建计算相关系数。发现改用pytorch-msssim之后的分数还没有原来的ssim的分数好；三个分数组合（过拟合了）也没有单用一个分数的好；用加权交叉熵训练后的模型可能也有过拟合的嫌疑，在训练集上分数有提升，但是在测试集上分数下降了。（后来官方的服务器修好后，发现和我自己的“服务器”的给的分数是差不多的。）</li>
<li>整理模型启动方法，环境配置方法，权重文件，发邮件备份</li>
</ul>
<ol start="2">
<li><strong>代办事项</strong></li>
</ol>
<ul>
<li>等它的 final test data release（但是到26号了咋还没有开放，29就好不就是最后的截止了吗，这个这个比赛的时间莫名其妙的）</li>
<li>我下一步的任务是啥，我要干啥？？是去修改模型架构吗（三个方向：输出浮点数；输入多张图像（三维处理为二维输入给llava）；多张图像输入给llava的视觉处理层，输出多个向量后，在多个向量叠加）（因为我发现我自己的相关系数评分测试和官网的评分服务器给的分很像，所以我可以去验证有效性）</li>
</ul>
<h4 id="问题和困难：-3"><a href="#问题和困难：-3" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li>主要是它的测试服务器从上周5晚上就坏了，然后一直到周2早上才好</li>
<li>还有就是没有预料到的改用pytorch-msssim为啥分数反而下降。</li>
<li>还有就是它的final test data咋还没有release啊</li>
</ul>
<h4 id="个人的感想和反思：-2"><a href="#个人的感想和反思：-2" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>主要的感觉是认为自己还不够细致；现在回想起来，踩了很多坑，比如我修改了我的权重文件的名字把里面的lora去掉了，然后就出了一些问题等等。而且，现在回想起来，应该先想清楚，然后在开始做（就比如之前的我一直都用的ssim，没有扣清楚原baseline到底是咋实现的，导致到现在了还没有实现；可能还有点擅自主张的就用了yuv444p等等之类的）。但回想起来，我也学习到了很多很多，一个月前还在用mac自带的终端跑大模型呢，现在我感觉自己已经可以很熟练的操作修改以及了解llava了。</p>
<h3 id="｜｜日期：2024-7-13-7-19"><a href="#｜｜日期：2024-7-13-7-19" class="headerlink" title="｜｜日期：2024.7.13-7.19"></a>｜｜日期：2024.7.13-7.19</h3><p>2024年7月13日 - 2024年7月19日</p>
<h4 id="本周工作内容：-4"><a href="#本周工作内容：-4" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><p><strong>目前成绩</strong><br>目标是把分数提高得越高越好。NR的效果(极大程度上）几乎就取决我的训练数据集。天花板就是我的“训练数据集伪标签方法的分数”（理想状态假设我的模型可以达到我的loss为0）。目前表现的最好的模型（10frame的忽视第一帧的黑白ms-ssim之后gt微调过的mp4转png的伪标签训练的模型）成绩为0.19527。天花板（mp4转png的ms-ssim全色彩方法，全frame取平均）的分数为0.30。</p>
</li>
<li><p><strong>核心问题</strong><br>问题瓶颈在天花板高度。提升方法：<br> 1.我需要更高的天花板方法。<br> 2.我需要我的模型去逼近天花板。</p>
</li>
<li><p><strong>改进方法</strong><br> 1.mp4转化为YUV的数据集和测试集；<br> 2.伪标签不需要gt微调，采用ms-ssim全色彩方法打标签；<br> 3.或者可以采取一些比ms-ssim更有效的方法指标，重点提升KROCC；（或者多指标融合）（看排行榜里：HIVE方法的KROCC很好的，但是大模型，搭建构建要点功夫（优先级可以放后一点）；或结合NIQE、PSNR ）<br> 按理说ms-ssim的天花板分数应该为：SROCC：0.98156；PLCC：0.96807；KROCC：0.93748；Results：0.53510<br> 5.伪标签可以减少学习的有效数字（应为loss是交叉熵，小数点后太多位了，但是每一位都是相同的权重，那些“不重要的数字”会干扰权重高的位置的数字的学习）；<br> 6.可以修改prompt来人为点制造“注意力机制”来教他用“哪根神经元”？？</p>
</li>
</ol>
<h4 id="项目结构："><a href="#项目结构：" class="headerlink" title="项目结构："></a>项目结构：</h4><ul>
<li><p>数据集&#x2F;测试集（.mp4) -&gt; 数据集&#x2F;测试集.yuv -&gt; 数据集&#x2F;测试集.png(evrey_15frame)</p>
</li>
<li><p>标签：全色彩ms-ssim打的伪标签取小数点后5位（现在想要和NIQE结合）</p>
</li>
<li><p>模型及训练：经过Q-instruct的llava；在数据集.png(evrey_15frame)上训练。输出一个分数。</p>
</li>
<li><p>在测试集.png(evrey_15frame)上出成绩。</p>
</li>
</ul>
<h4 id="最新进度："><a href="#最新进度：" class="headerlink" title="最新进度："></a>最新进度：</h4><p>重新配置总结了配置模型运行、训练环境需要下载哪些包；；<br>已经把数据集&#x2F;测试集转化为了.yuv，并已经提取出来数据集&#x2F;测试集.png(evrey_15frame)。 已经用全色彩ms-ssim和NIQE给我的测试集.png(evrey_15frame)打了标签，在测试怎么组合最佳。</p>
<h4 id="待办事项："><a href="#待办事项：" class="headerlink" title="待办事项："></a>待办事项：</h4><p>ms-ssmi给数据集打标签&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;<br>NIQE给数据集打标签&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;      或者测试两个组合标签<br>测试两者组合&#x2F;&#x2F;&#x2F;&#x2F;&#x2F;</p>
<p>给出一个最合适的数据集标签（小数点后5位）</p>
<p>训练（基础模型的选择）</p>
<p>在测试集上测试</p>
<h4 id="总结一下核心模型的迭代过程："><a href="#总结一下核心模型的迭代过程：" class="headerlink" title="总结一下核心模型的迭代过程："></a>总结一下核心模型的迭代过程：</h4><p>llava-v1.5-7b-qinstruct-myown-after ： 每个视频随机提取一帧 GT标签 训练的  jpg （0.01）<br>llava-v1.5-7b-qinstruct-myown-after-fakelable：每张视频随机提取10帧 让上一任模型打了伪标签(gt分数上微调） png<br>llava-v1.5-7b-finally-merged：目前表现最好的一个模型（0.195），是在黑白msssim（且在gt微调）打的伪标签训练的 png<br>llava-v1.5-7b-finally-merged-mssim：在上一任模型为基础上，在彩色原始msssim分数上伪标签训练的（0.154）png</p>
<h4 id="未解决的困难："><a href="#未解决的困难：" class="headerlink" title="未解决的困难："></a>未解决的困难：</h4><ul>
<li><p>想要用vllm加速推理，但是我尝试了一些，目前没有找到一个vllm可以我的llava的pythorch、cuda、transform等是完全比配的。</p>
</li>
<li><p>ms-ssim的分数怎么和niqe的分数融合啊？（前者0-1，越大越好；后者0-正无穷，学校越好）<br>我尝试了（mssim+alpha&#x2F;niqe ）<br>mssim  |0.95363	|0.98105	|0.86874	|0.30395<br>niqe   |0.26983	|0.29330	|0.22612	|0.00000<br>alpha&#x3D;0.1  |0.95377	｜0.98116   ｜0.86832	  ｜0.30357<br>0.5      ｜0.96108	｜0.97831  ｜0.87418  ｜0.32749</p>
</li>
<li><p>应为以上提到的模型都是输出为0-10.然后我尝试用llava-v1.5-7b-finally-merged作为基础模型，之际诶在彩色原始msssim分数（范围是0-1）上训练。但是在训练完后，他的输出还是0-10的（就有稍微的分值变化）。我在想要怎么搞才能让我的模型直接学习到彩色原始msssim分数？是不是要重来（或者用llava-v1.5-7b-qinstruct-myown-after作为基础模型）？还是只是我的训练时间不够？？（但是我看它的loss也收敛了呀已经）</p>
</li>
</ul>
<h4 id="个人的感想和反思：-3"><a href="#个人的感想和反思：-3" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>时间安排的很好，机器利用效率很高，几乎让它一直处于运作状态。<br>成绩提升很快，但仍有上升空间。但遇到瓶颈了。</p>
<h3 id="｜｜日期：2024-7-6-7-12"><a href="#｜｜日期：2024-7-6-7-12" class="headerlink" title="｜｜日期：2024.7.6-7.12"></a>｜｜日期：2024.7.6-7.12</h3><p>2024年7月6日 - 2024年7月12日</p>
<h4 id="本周工作内容：-5"><a href="#本周工作内容：-5" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><strong>完成的任务</strong></li>
</ol>
<ul>
<li>测试脚本的编写</li>
<li>第一稿模型跑测试（结果：0.01287）</li>
<li>数据集完善（png格式、每个视频10帧）。以及其info_10per.json的编写。伪标签策略（用我的第一稿模型来给我的数据集（1个视频对应10张图片）打上伪标签，并加入偏移量调整使得10张图片的伪标签分数的平均值是视频的真实分数）。</li>
<li>第二稿模型跑测试（结果：0.05522）</li>
</ul>
<ol start="2">
<li><strong>正在进行的任务</strong></li>
</ol>
<ul>
<li>改模型输出到浮点数    <details><br>  <summary>过程</summary><ol>
<li><p><strong>修改模型输出为浮点数</strong>：</p>
<ul>
<li><strong>最后一层修改</strong>：将原来输出到词汇表（vocab_size）的全连接层修改为输出单个浮点数的层。</li>
<li><strong>输出形状修改</strong>：输出的形状应该是 <code>(batch_size*1, 1)</code>，其中 <code>1</code> 表示单个浮点数值。</li>
</ul>
</li>
<li><p><strong>修改损失函数为 MSE</strong>：</p>
<ul>
<li>使用均方误差（MSE）损失函数来比较模型输出和标签（answer）之间的距离。</li>
</ul>
</li>
<li><p><strong>数据处理修改</strong>：</p>
<ul>
<li>不再需要将答案（labels）转换为 tokens 或 embeddings。直接使用答案作为标签即可。</li>
</ul>
</li>
<li><p><strong>权重加载和保存处理</strong>：</p>
<ul>
<li><strong>加载权重处理</strong>：确保加载函数只加载与新模型结构兼容的部分，手动初始化新添加层的参数。</li>
<li><strong>保存权重处理</strong>：保存模型时只保存参数状态即可，无需修改保存代码。</li>
</ul>
</li>
</ol>
</li>
</ul>
</details>

<details>
        <summary>担心</summary>
   当我修改了模型结构之后，我的之前预训练好的权重，将离我的新的最优解很远吧，因为逻辑全都变了，我之前的权重都是相当于都是为了理解文本啊，等等的功能的神经单元。但现在我改为了其他的任务，就输出一个浮点数，那么这些神经单元都没用啊，那我是不是很难收敛啊，相当于这些神经单元的参数需要大变化来适应我的新任务啊。 但话又说回来，我的任务实际上变得很简单了吧，那么多个参数最后就映射到一个浮点数的输出上，那实际上我的效果和参数其实应该很好收敛？？
    
<p>😭感觉要调试改的地方好多，而且改完之后训练的话也不知道要不要很长时间啊（这相当于要重新开始训模型？？而且原来预训练好的权重都没用？效果也不知道会不会变好？）</p>
</details>

<ul>
<li>找找有没有其他的优化方法</li>
<li><ul>
<li>多实例学习（模型最开始加一个类似三维卷积的层，聚合采样的10帧的图像，再把输入再变成2维的喂给llava“解决）</li>
</ul>
</li>
</ul>
<ol start="3">
<li><strong>待办事项</strong></li>
</ol>
<h4 id="学到的新的小知识或技能：-3"><a href="#学到的新的小知识或技能：-3" class="headerlink" title="学到的新的小知识或技能："></a>学到的新的小知识或技能：</h4><ul>
<li>优化步骤拆解一下，从数据，模型训练，到测试方法</li>
<li><ul>
<li>数据：数据增广(伪标签)，加噪增强（训练图片加噪，加高斯噪声椒盐噪声什么的），怎么从视频里边抽取更多的有效帧，怎么合到模型里边。效果提升最快的永远是加数据（第二是一个视频是300帧，你现在只用1帧，肯定用的更多效果会更好）；多实例学习，采样10帧，拼成一个输入一起送给模型，让模型自己去学（在模型最开始加一个类似三维卷积的层，把输入再变成2维的）</li>
</ul>
</li>
<li>llama模型的结构。包括各种小知识的学习：tokens、embedding、transformer层，forward、backward层，输出层原理（hidden states经过全连接层，到logits三维tensor（到字典层），二维化后可以算loss）</li>
</ul>
<h4 id="问题和困难：-4"><a href="#问题和困难：-4" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li>调试改输出层和loss，不明原因，一直报错，疯了。#解决方案：找学长帮我看看</li>
</ul>
<h4 id="个人的感想和反思：-4"><a href="#个人的感想和反思：-4" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>之前的任务可能就写写脚本，改改数据集，模仿别人的微调方法自己微调，感觉还算容易。但当涉及到了真正的去改模型的结构之类的，可以明显的感觉到难度变高了。在求助学长学姐的同时，也发现自己需要去学的关于模型结构以及实现知识还有很多（很多时候都听不懂他们在讲啥😭）。但急不得，也不用去给自己很多压力，已经尽力了就好。还是需要更细致的去理解每一个东西才行，而且需要去补基础知识。</p>
<h3 id="｜｜日期：2024-6-29-7-5"><a href="#｜｜日期：2024-6-29-7-5" class="headerlink" title="｜｜日期：2024.6.29-7.5"></a>｜｜日期：2024.6.29-7.5</h3><p>2024年6月29日 - 2024年7月5日</p>
<h4 id="本周工作内容：-6"><a href="#本周工作内容：-6" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><strong>完成的任务</strong></li>
</ol>
<ul>
<li><p>下载比赛官方数据集</p>
</li>
<li><p>模型结构设计并搭建实现它</p>
<details>
  将视频分解成帧。每一帧图像质量评估成分数。将这些质量评分进行平均，作为视频的整体质量评分。
 </details>
 </li>
<li><p>用Q-instruct训练好的llava模型</p>
</li>
<li><p>生成训练的数据（因为我的模型的视频的质量输出其实就是对图片s的质量的平均。那也就是说我需要让他的输出的图片质量的数值逼近视频质量的ground truth的数值）（对每个视频随机抽取一帧）</p>
 <details>
     <summary>生成info.json的代码</summary>
     代码：
 
<pre><code class="hljs"> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> csv<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-comment"># 文件路径</span><br>csv_file_path = <span class="hljs-string">&#x27;/mnt/data/Subjective_scores_train.csv&#x27;</span><br>json_file_path = <span class="hljs-string">&#x27;/mnt/data/info.json&#x27;</span><br><br><span class="hljs-comment"># 多样化的human指令</span><br>human_instructions = [<br>    <span class="hljs-string">&quot;&lt;image&gt;\nPlease assess the image quality based on factors like clarity, detail, structure, and color. Provide a numerical score between 0.00 and 10.00.&quot;</span>,<br>    <span class="hljs-string">&quot;&lt;image&gt;\nEvaluate the image quality focusing on sharpness, preservation of details, structural integrity, and color fidelity. Give a score from 0.00 to 10.00.&quot;</span>,<br>    <span class="hljs-string">&quot;&lt;image&gt;\nYou are an image quality assessment tool. Score the image quality on a scale from 0.00 to 10.00, considering clarity, detail, structure, and color.&quot;</span>,<br>    <span class="hljs-string">&quot;&lt;image&gt;\nBased on clarity, detail retention, structural coherence, and color accuracy, assign a quality score between 0.00 and 10.00 to the image.&quot;</span>,<br>    <span class="hljs-string">&quot;&lt;image&gt;\nAssess the image quality by considering its sharpness, detail preservation, structural integrity, and color accuracy. Provide a score from 0.00 to 10.00.&quot;</span><br>]<br><br><span class="hljs-comment"># 函数：根据CSV中的一行创建一个图像条目</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_image_entry</span>(<span class="hljs-params">row</span>):<br>    codec, preset, sequence, crf, standard, real_bitrate, bitrate, subjective_score = row<br>    subjective_score = <span class="hljs-built_in">float</span>(subjective_score)<br><br>    image_id = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;sequence.replace(<span class="hljs-string">&#x27;-&#x27;</span>, <span class="hljs-string">&#x27;_&#x27;</span>)&#125;</span>_<span class="hljs-subst">&#123;preset&#125;</span>_<span class="hljs-subst">&#123;codec&#125;</span>_<span class="hljs-subst">&#123;crf&#125;</span>&quot;</span><br>    image_path = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;sequence&#125;</span>/<span class="hljs-subst">&#123;preset&#125;</span>/<span class="hljs-subst">&#123;codec&#125;</span>_<span class="hljs-subst">&#123;crf&#125;</span>.jpg&quot;</span><br>    human_instruction = random.choice(human_instructions)<br>    gpt_output = <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;subjective_score:<span class="hljs-number">.2</span>f&#125;</span>&quot;</span><br><br>    <span class="hljs-keyword">return</span> &#123;<br>        <span class="hljs-string">&quot;id&quot;</span>: image_id,<br>        <span class="hljs-string">&quot;image&quot;</span>: image_path,<br>        <span class="hljs-string">&quot;conversations&quot;</span>: [<br>            &#123;<br>                <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-string">&quot;human&quot;</span>,<br>                <span class="hljs-string">&quot;value&quot;</span>: human_instruction<br>            &#125;,<br>            &#123;<br>                <span class="hljs-string">&quot;from&quot;</span>: <span class="hljs-string">&quot;gpt&quot;</span>,<br>                <span class="hljs-string">&quot;value&quot;</span>: gpt_output<br>            &#125;<br>        ]<br>    &#125;<br><br><span class="hljs-comment"># 读取CSV文件并转换为JSON格式</span><br>image_entries = []<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(csv_file_path, newline=<span class="hljs-string">&#x27;&#x27;</span>) <span class="hljs-keyword">as</span> csvfile:<br>    csvreader = csv.reader(csvfile)<br>    header = <span class="hljs-built_in">next</span>(csvreader)  <span class="hljs-comment"># 跳过表头</span><br>    <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> csvreader:<br>        image_entry = create_image_entry(row)<br>        image_entries.append(image_entry)<br><br><span class="hljs-comment"># 将结果保存为JSON文件</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(json_file_path, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> jsonfile:<br>    json.dump(image_entries, jsonfile, indent=<span class="hljs-number">4</span>)<br></code></pre></td></tr></table></figure>
</code></pre>
 </details>
 
<ul>
<li>用自己的数据集（指令微调）训练好模型</li>
</ul>
</li>
</ul>
<ol start="2">
<li><strong>正在进行的任务</strong></li>
</ol>
<ul>
<li>额外数据集的选择。<details><summary>问题</summary>Q-bench的a3_iqa数据集,>Q-bench的a3_iqa数据集, 它里面的数据集用哪个？这7个数据集为啥之间的评分差别那么大？（它的主观评分可信（可用）吗？？）</details></li>
<li>模型结构需要改吗？？那个逻辑好像对数字的逼近不太符合，但是llava这种大模型loss可以改吗？需要改嘛？怎么改？（去改loss的想法是个good idea吗？）<details><summary>问题</summary>如果我是想要让我的llava模型在某个指令上finetune只输出数字 然后 要和我的目标数字越接近越好，那我的loss咋设计？？或者说我可以咋改变我的模型结构？？但话又说回来，我只是指令微调啊，不合适改变整个模型的loss吧。
</details></li>
</ul>
<ol start="3">
<li><strong>待办事项</strong></li>
</ol>
<ul>
<li>用额外的数据集训练模型</li>
<li>用比赛提供的benchmark测评最终模型效果</li>
<li>想一下可以咋优化我的提示（一方面给出更详细的指导，另一方面说不定可以利用链式思维）</li>
</ul>
<h4 id="学到的新的小知识或技能：-4"><a href="#学到的新的小知识或技能：-4" class="headerlink" title="学到的新的小知识或技能："></a>学到的新的小知识或技能：</h4><ul>
<li>详细认识了Q-instruct数据集，以及如何用它微调llava</li>
<li>NR-IQA 模型严重依赖训练数据，在面对更广泛的图像和失真时，这通常表现出弱泛化。（A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment）</li>
<li>NR-IQA的评分可能会出现不准确性和上下文依赖性（A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment）</li>
<li>使用 MLLM 的推理往往很慢且昂贵，论文中提的九个提示系统配对的完整 IQA 数据集上评估 MLLM 是不切实际的。论文中提出来了了一个计算过程，以确定一组更小的信息量最大的样本，这些样本满足三个关键标准。（A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment）</li>
<li>一些工程使用实践上的经验，比如：熟练的配环境，python的使用，vscode的一些有用的功能的发现等等。</li>
<li>利用python来进行数据的处理，标签的处理，字典列表的生成。</li>
<li>可以利用chatgpt-4o进行把原始数据集转化为指令微调数据集</li>
</ul>
<h4 id="问题和困难：-5"><a href="#问题和困难：-5" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li><p><del>视频质量评分的subjective_score分值范围是什么，评估角度和标准是什么。</del></p>
 <details> 
 - - 根据其个人感知和经验，给视频质量打分。通常分数从1到5或1到10不等，其中较高分数表示更好的质量。
  - - 考虑视频的多个方面，如画面质量、音频质量（如果适用）、播放流畅性等因素。
</details>
 </li>
<li><p><del>q-instruct论文里提供的权重的它的readme里面说“This is a preview version ofthe O-Instruct LLaVA.Non-finalized weights”开始不确定能不能用，想着干脆自己训练一遍，但是后来发现自己训练要6天的时间，时间太长。最后我认为它这么说就是一个：就是个“免责声明”（怕有人拿这个模型，说和你论文结果对不上）。就直接拿他的权重来用吧。</del></p>
</li>
<li><p>这个是过拟合吗？？</p>
 <details>
 <summary>image</summary>
 ![](https://notes.sjtu.edu.cn/uploads/upload_4b5e61a565a8f70196382b6cd7ad9ad2.png)

 </details></li>
</ul>
<h4 id="个人的感想和反思：-5"><a href="#个人的感想和反思：-5" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>总体感觉进行的很顺利，时间安排也蛮好的，继续加油吧。</p>
<h3 id="｜｜日期：2024-6-24-6-28"><a href="#｜｜日期：2024-6-24-6-28" class="headerlink" title="｜｜日期：2024.6.24-6.28"></a>｜｜日期：2024.6.24-6.28</h3><p>2024年6月24日 - 2024年6月28日</p>
<h4 id="本周工作内容：-7"><a href="#本周工作内容：-7" class="headerlink" title="本周工作内容："></a>本周工作内容：</h4><ol>
<li><p><strong>完成的任务</strong></p>
<ul>
<li>匹配了（5个）数据集对应的（14个）基准测试。</li>
<li>直接下载使用官方的模型在VisWiz上评估，并和官方模型的结果比较，结果一致。（文档里说是50.0分，我测的是50.38分）</li>
<li>浅层地了解了改进LLaVA结构中“projection layer”的线性层的方法：Q-former（文本特征（query）通过注意力机制与图像特征（key 和 value）进行交互）</li>
<li>看VQA的比赛要求</li>
<li>论文IQAGPT: Image Quality Assessment with Vision-language and ChatGPT Models</li>
<li><ul>
<li>灵感点：是找到了一个实用的痛点（跨学科）“放射科医生进行的传统主观CT图像质量评估程序”</li>
</ul>
</li>
<li><ul>
<li>数据集：1000张有人工评分和生成的文本描述</li>
</ul>
</li>
<li><ul>
<li>模型：预训练的医学VLM和微调在CT-IQA数据集上通过跨模态注意力融合图像和文本特征</li>
</ul>
</li>
<li><ul>
<li>聪明的技巧：提高熵。虽然目的是生成分数，却不直接用分数来训练模型，而是把分数转化为详细的描述（包含更多的信息），来训练模型，然后在转化为分数。</li>
</ul>
</li>
<li>论文A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment</li>
<li><ul>
<li>LLaVA只能处理单张图片的输入，对多张输入图片的任务不行。</li>
</ul>
</li>
<li><ul>
<li>多模态模型相对于“质量测评专家”模型有优势</li>
</ul>
</li>
<li><ul>
<li>基于对LLaVA微调过的模型Q-instruct效果很厉害！（说明我们的去对LLaVA微调的想法是有效果的！！）</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>正在进行的任务</strong></p>
<ul>
<li>清理服务器硬盘里的不需要的文件</li>
<li>自己训练的（COCO数据集下的）模型在MM-vet上评估，并和官方模型的结果比较。（我已经得到了我自己模型interface的答案，但它需要GPT-4辅助评估打分，还在琢磨咋搞）</li>
</ul>
</li>
<li><p><strong>待办事项</strong></p>
<ul>
<li>看Q-instruct的论文，并参考其原理为那个比赛可以自己去tune LLaVA</li>
<li>视频质量评估模型比赛的数据集下载（什么数据集？那个官方的视频数据集吗？LLaVA只能处理图像输入，那个数据集怎么利用？可以输入图片在加上时间？？）</li>
<li>数据集下载 数据处理。</li>
</ul>
</li>
</ol>
<h4 id="学到的新的小知识或技能：-5"><a href="#学到的新的小知识或技能：-5" class="headerlink" title="学到的新的小知识或技能："></a>学到的新的小知识或技能：</h4><ul>
<li>搞清楚了epoches、batch的作用和效果。</li>
<li>知道了为啥llava用的是llama而不是gpt-4  <details>
<summary>细节</summary>
  llama开源， gpt-4只能API访问。
  </details></li>
<li>LLaVA-1.5模型在多个基准测试集上进行评估时，采用了贪婪解码方法以保证评估结果的可复现性，并且没有使用束搜索以保持与实时聊天演示的一致性。此外，他们主要使用官方提供的工具和服务器进行评估，以确保标准化。</li>
<li>Minigpt-4和LLaVA的实现原理很像（两者对比可以在这里找到：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39388410/article/details/130772680%EF%BC%89">https://blog.csdn.net/qq_39388410/article/details/130772680）</a></li>
<li>9种提示方法(刺激、双刺激、多刺激)*(the standard, in-context, and chain-of-thought prompting)</li>
<li>一些不同的benchmark怎么去使用。比如：VQAv2、VisWiz、MME、MMBench</li>
</ul>
<h4 id="问题和困难：-6"><a href="#问题和困难：-6" class="headerlink" title="问题和困难："></a>问题和困难：</h4><ul>
<li>需要下载的数据集太大了，服务器硬盘不够。&#x2F;&#x2F;解决方案：升级租的硬盘空间的大小</li>
<li>在MM-vet评估时候，需要GPT-4辅助评估，需要自己写一些脚本先来抽取整理数据。</li>
<li>在看论文里和VQA比赛要求里的都有很多‘专有名词’和‘一些数学的东西’，都没有接触过，遇到重要的都要一个一个查，虽然都看下来了一遍但是感觉没有完全看懂，要补的知识还有很多很多。&#x2F;&#x2F;解决方案：先宏观，不去纠结每个细节，细节慢慢再补。</li>
</ul>
<h4 id="个人的感想和反思：-6"><a href="#个人的感想和反思：-6" class="headerlink" title="个人的感想和反思："></a>个人的感想和反思：</h4><p>这个星期，花在学习这个上面的时间减少了一些（因为花了很多时间在朋友的毕业saygoodbye上），但又同时想完成所有任务，导致任务量分配到每天不均匀。前几天轻松，后几天却很累。我需要调整状态，投入更多时间（比赛时间很紧张！），然后更加合理分配时间。</p>
<h3 id="模版"><a href="#模版" class="headerlink" title="模版"></a>模版</h3><pre><code class="hljs">### ｜｜日期：2024.7.6-7.13
2024年7月6日 - 2024年7月13日

#### 本周工作内容：
1. **完成的任务**

2. **正在进行的任务**

3. **待办事项**

#### 学到的新的小知识或技能：


#### 问题和困难：


#### 个人的感想和反思：
</code></pre>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>周报</div>
      <div>http://example.com/2024/08/18/周报/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jiahao Xiao</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年8月18日</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>更新于</div>
          <div>2024年8月30日</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/logs_weekly/2024/08/18/hello-world/" title="Hello World">
                        <span class="hidden-mobile">Hello World</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/logs_weekly/js/events.js" ></script>
<script  src="/logs_weekly/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/logs_weekly/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/logs_weekly/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/logs_weekly/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
